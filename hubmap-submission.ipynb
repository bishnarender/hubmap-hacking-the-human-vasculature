{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72faa1b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:45:52.927965Z",
     "iopub.status.busy": "2023-08-29T14:45:52.927513Z",
     "iopub.status.idle": "2023-08-29T14:45:52.933264Z",
     "shell.execute_reply": "2023-08-29T14:45:52.932361Z"
    },
    "papermill": {
     "duration": 0.017226,
     "end_time": "2023-08-29T14:45:52.936406",
     "exception": false,
     "start_time": "2023-08-29T14:45:52.919180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this file is a modified version of the original:\n",
    "# https://www.kaggle.com/tascj0/hubmap-2023-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a290b416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:45:52.951303Z",
     "iopub.status.busy": "2023-08-29T14:45:52.949745Z",
     "iopub.status.idle": "2023-08-29T14:47:17.749253Z",
     "shell.execute_reply": "2023-08-29T14:47:17.747921Z"
    },
    "papermill": {
     "duration": 84.810153,
     "end_time": "2023-08-29T14:47:17.752767",
     "exception": false,
     "start_time": "2023-08-29T14:45:52.942614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q --no-index /kaggle/input/hubmap-resources/mmdetv3_env/archive/addict-2.4.0-py3-none-any.whl\n",
    "# !pip install -q --no-index /kaggle/input/mmdetv3_env/archive/mmengine-0.7.4-py3-none-any.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/vasculature-packages/mmengine-0.8.3-py3-none-any.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/mmdetv3_env/archive/mmcv-2.0.0-cp310-cp310-linux_x86_64.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/mmdetv3_env/archive/terminaltables-3.1.10-py2.py3-none-any.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/pycocotools_2.0.6/wheels/pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/mmdetection-3-1-evn/src/mmdet-3.1.0-py3-none-any.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/vasculature-packages/ensemble_boxes-1.0.9-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cf58bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:47:17.767185Z",
     "iopub.status.busy": "2023-08-29T14:47:17.766849Z",
     "iopub.status.idle": "2023-08-29T14:48:06.795655Z",
     "shell.execute_reply": "2023-08-29T14:48:06.794444Z"
    },
    "papermill": {
     "duration": 49.03885,
     "end_time": "2023-08-29T14:48:06.798129",
     "exception": false,
     "start_time": "2023-08-29T14:47:17.759279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/hubmap-resources/vasculature-packages/mmpretrain-1.0.1-py2.py3-none-any.whl\r\n",
      "Installing collected packages: mmpretrain\r\n",
      "Successfully installed mmpretrain-1.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --no-index /kaggle/input/hubmap-resources/vasculature-packages/ordered_set-4.1.0-py3-none-any.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/vasculature-packages/model_index-0.1.11-py3-none-any.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/vasculature-packages/einops-0.6.1-py3-none-any.whl\n",
    "!pip install -q --no-index /kaggle/input/hubmap-resources/vasculature-packages/mat4py-0.5.0-py2.py3-none-any.whl\n",
    "!pip install --no-deps --no-index /kaggle/input/hubmap-resources/vasculature-packages/mmpretrain-1.0.1-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d05fbc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:48:06.814712Z",
     "iopub.status.busy": "2023-08-29T14:48:06.813052Z",
     "iopub.status.idle": "2023-08-29T14:48:07.109117Z",
     "shell.execute_reply": "2023-08-29T14:48:07.108144Z"
    },
    "papermill": {
     "duration": 0.306788,
     "end_time": "2023-08-29T14:48:07.111766",
     "exception": false,
     "start_time": "2023-08-29T14:48:06.804978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import mmengine\n",
    "\n",
    "\n",
    "def prepare_dataset():\n",
    "    coco = {\n",
    "        'info': {},\n",
    "        'categories': [{\n",
    "            'id': 0,\n",
    "            'name': 'blood_vessel',\n",
    "        },{\n",
    "            'id': 1,\n",
    "            'name': 'glomerulus',\n",
    "        },{\n",
    "            'id': 2,\n",
    "            'name': 'unsure'\n",
    "        }],\n",
    "        'annotations': []\n",
    "    }\n",
    "    test_imgs = glob.glob('/kaggle/input/hubmap-hacking-the-human-vasculature/test/*.tif')\n",
    "    img_infos = []\n",
    "    img_id = 0\n",
    "    for path in test_imgs:\n",
    "        filename = os.path.basename(path)\n",
    "        img_info = dict(\n",
    "            id=img_id,\n",
    "            width=512,\n",
    "            height=512,\n",
    "            file_name=filename,\n",
    "        )\n",
    "        img_infos.append(img_info)\n",
    "        img_id += 1\n",
    "    coco['images'] = img_infos\n",
    "    return coco\n",
    "\n",
    "\n",
    "mmengine.dump(prepare_dataset(), '/kaggle/working/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263f72d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:48:07.127003Z",
     "iopub.status.busy": "2023-08-29T14:48:07.126710Z",
     "iopub.status.idle": "2023-08-29T14:48:07.136324Z",
     "shell.execute_reply": "2023-08-29T14:48:07.135449Z"
    },
    "papermill": {
     "duration": 0.01978,
     "end_time": "2023-08-29T14:48:07.138576",
     "exception": false,
     "start_time": "2023-08-29T14:48:07.118796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "\n",
    "from mmengine import ConfigDict\n",
    "from mmengine.config import Config, DictAction\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "from mmdet.engine.hooks.utils import trigger_visualization_hook\n",
    "from mmdet.evaluation import DumpDetResults\n",
    "from mmdet.registry import RUNNERS\n",
    "from mmdet.utils import setup_cache_size_limit_of_dynamo\n",
    "\n",
    "\n",
    "# TODO: support fuse_conv_bn and format_only\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='MMDet test (and eval) a model')\n",
    "    parser.add_argument('config', help='test config file path')\n",
    "    parser.add_argument('checkpoint', help='checkpoint file')\n",
    "    parser.add_argument(\n",
    "        '--work-dir',\n",
    "        help='the directory to save the file containing evaluation metrics')\n",
    "    parser.add_argument(\n",
    "        '--out',\n",
    "        type=str,\n",
    "        help='dump predictions to a pickle file for offline evaluation')\n",
    "    parser.add_argument(\n",
    "        '--show', action='store_true', help='show prediction results')\n",
    "    parser.add_argument(\n",
    "        '--show-dir',\n",
    "        help='directory where painted images will be saved. '\n",
    "        'If specified, it will be automatically saved '\n",
    "        'to the work_dir/timestamp/show_dir')\n",
    "    parser.add_argument(\n",
    "        '--wait-time', type=float, default=2, help='the interval of show (s)')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. If the value to '\n",
    "        'be overwritten is a list, it should be like key=\"[a,b]\" or key=a,b '\n",
    "        'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n",
    "        'Note that the quotation marks are necessary and that no white space '\n",
    "        'is allowed.')\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--tta', action='store_true')\n",
    "    # When using PyTorch version >= 2.0.0, the `torch.distributed.launch`\n",
    "    # will pass the `--local-rank` parameter to `tools/train.py` instead\n",
    "    # of `--local_rank`.\n",
    "    parser.add_argument('--local_rank', '--local-rank', type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    # Reduce the number of repeated compilations and improve\n",
    "    # testing speed.\n",
    "    setup_cache_size_limit_of_dynamo()\n",
    "\n",
    "    # load config\n",
    "    cfg = Config.fromfile(args.config)\n",
    "    cfg.launcher = args.launcher\n",
    "    if args.cfg_options is not None:\n",
    "        cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "    # work_dir is determined in this priority: CLI > segment in file > filename\n",
    "    if args.work_dir is not None:\n",
    "        # update configs according to CLI args if args.work_dir is not None\n",
    "        cfg.work_dir = args.work_dir\n",
    "    elif cfg.get('work_dir', None) is None:\n",
    "        # use config filename as default work_dir if cfg.work_dir is None\n",
    "        cfg.work_dir = osp.join('./work_dirs',\n",
    "                                osp.splitext(osp.basename(args.config))[0])\n",
    "\n",
    "    if args.checkpoint != 'none':\n",
    "        cfg.load_from = args.checkpoint\n",
    "\n",
    "    if args.show or args.show_dir:\n",
    "        cfg = trigger_visualization_hook(cfg, args)\n",
    "\n",
    "    if args.tta:\n",
    "\n",
    "        if 'tta_model' not in cfg:\n",
    "            warnings.warn('Cannot find ``tta_model`` in config, '\n",
    "                          'we will set it as default.')\n",
    "            cfg.tta_model = dict(\n",
    "                type='DetTTAModel',\n",
    "                tta_cfg=dict(\n",
    "                    nms=dict(type='nms', iou_threshold=0.5), max_per_img=100))\n",
    "        if 'tta_pipeline' not in cfg:\n",
    "            warnings.warn('Cannot find ``tta_pipeline`` in config, '\n",
    "                          'we will set it as default.')\n",
    "            test_data_cfg = cfg.test_dataloader.dataset\n",
    "            while 'dataset' in test_data_cfg:\n",
    "                test_data_cfg = test_data_cfg['dataset']\n",
    "            cfg.tta_pipeline = deepcopy(test_data_cfg.pipeline)\n",
    "            flip_tta = dict(\n",
    "                type='TestTimeAug',\n",
    "                transforms=[\n",
    "                    [\n",
    "                        dict(type='RandomFlip', prob=1.),\n",
    "                        dict(type='RandomFlip', prob=0.)\n",
    "                    ],\n",
    "                    [\n",
    "                        dict(\n",
    "                            type='PackDetInputs',\n",
    "                            meta_keys=('img_id', 'img_path', 'ori_shape',\n",
    "                                       'img_shape', 'scale_factor', 'flip',\n",
    "                                       'flip_direction'))\n",
    "                    ],\n",
    "                ])\n",
    "            cfg.tta_pipeline[-1] = flip_tta\n",
    "        cfg.model = ConfigDict(**cfg.tta_model, module=cfg.model)\n",
    "        cfg.test_dataloader.dataset.pipeline = cfg.tta_pipeline\n",
    "\n",
    "    # build the runner from config\n",
    "    if 'runner_type' not in cfg:\n",
    "        # build the default runner\n",
    "        runner = Runner.from_cfg(cfg)\n",
    "    else:\n",
    "        # build customized runner from the registry\n",
    "        # if 'runner_type' is set in the cfg\n",
    "        runner = RUNNERS.build(cfg)\n",
    "\n",
    "    # add `DumpResults` dummy metric\n",
    "    if args.out is not None:\n",
    "        assert args.out.endswith(('.pkl', '.pickle')), \\\n",
    "            'The dump file must be a pkl file.'\n",
    "        runner.test_evaluator.metrics.append(\n",
    "            DumpDetResults(out_file_path=args.out))\n",
    "\n",
    "    # start testing\n",
    "    runner.test()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e56fc1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:48:07.152641Z",
     "iopub.status.busy": "2023-08-29T14:48:07.152296Z",
     "iopub.status.idle": "2023-08-29T14:48:08.111530Z",
     "shell.execute_reply": "2023-08-29T14:48:08.110203Z"
    },
    "papermill": {
     "duration": 0.969392,
     "end_time": "2023-08-29T14:48:08.114286",
     "exception": false,
     "start_time": "2023-08-29T14:48:07.144894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/hubmap-resources/custom-modules /kaggle/working/hubmap_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b972e13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:48:08.129654Z",
     "iopub.status.busy": "2023-08-29T14:48:08.128780Z",
     "iopub.status.idle": "2023-08-29T14:48:09.073233Z",
     "shell.execute_reply": "2023-08-29T14:48:09.071841Z"
    },
    "papermill": {
     "duration": 0.95464,
     "end_time": "2023-08-29T14:48:09.075801",
     "exception": false,
     "start_time": "2023-08-29T14:48:08.121161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  rtmdet_mask.py  yolox_mask.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/hubmap_modules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd636dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:48:09.091802Z",
     "iopub.status.busy": "2023-08-29T14:48:09.090769Z",
     "iopub.status.idle": "2023-08-29T14:49:16.479715Z",
     "shell.execute_reply": "2023-08-29T14:49:16.478461Z"
    },
    "papermill": {
     "duration": 67.399552,
     "end_time": "2023-08-29T14:49:16.482265",
     "exception": false,
     "start_time": "2023-08-29T14:48:09.082713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\r\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\r\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\r\n",
      "08/29 14:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\r\n",
      "    CUDA available: True\r\n",
      "    numpy_random_seed: 1513038381\r\n",
      "    GPU 0: Tesla P100-PCIE-16GB\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\r\n",
      "    GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0\r\n",
      "    PyTorch: 2.0.0\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 11.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 11.8\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_70,code=compute_70;-gencode;arch=compute_75,code=compute_75\r\n",
      "  - CuDNN 8.9\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.15.1\r\n",
      "    OpenCV: 4.8.0\r\n",
      "    MMEngine: 0.8.3\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1513038381\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "08/29 14:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\r\n",
      "backend_args = None\r\n",
      "custom_imports = dict(\r\n",
      "    allow_failed_imports=False, imports=[\r\n",
      "        'hubmap_modules',\r\n",
      "    ])\r\n",
      "data_root = '/kaggle/working/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "img_prefix = '/kaggle/input/hubmap-hacking-the-human-vasculature/test/'\r\n",
      "img_scale = (\r\n",
      "    1280,\r\n",
      "    1280,\r\n",
      ")\r\n",
      "launcher = 'none'\r\n",
      "load_from = '/kaggle/input/hubmap-weights/weights-hubmap/m0i.pth'\r\n",
      "metainfo = dict(classes=(\r\n",
      "    'blood_vessel',\r\n",
      "    'glomerulus',\r\n",
      "    'unsure',\r\n",
      "))\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        attn_drop_rate=0.0,\r\n",
      "        convert_weights=True,\r\n",
      "        depths=[\r\n",
      "            2,\r\n",
      "            2,\r\n",
      "            18,\r\n",
      "            2,\r\n",
      "        ],\r\n",
      "        drop_path_rate=0.2,\r\n",
      "        drop_rate=0.0,\r\n",
      "        embed_dims=96,\r\n",
      "        mlp_ratio=4,\r\n",
      "        num_heads=[\r\n",
      "            3,\r\n",
      "            6,\r\n",
      "            12,\r\n",
      "            24,\r\n",
      "        ],\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        patch_norm=True,\r\n",
      "        qk_scale=None,\r\n",
      "        qkv_bias=True,\r\n",
      "        type='SwinTransformer',\r\n",
      "        window_size=7,\r\n",
      "        with_cp=False),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=True,\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        pad_mask=True,\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            96,\r\n",
      "            192,\r\n",
      "            384,\r\n",
      "            768,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=3,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        mask_head=dict(\r\n",
      "            conv_out_channels=256,\r\n",
      "            in_channels=256,\r\n",
      "            loss_mask=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "            num_classes=3,\r\n",
      "            num_convs=4,\r\n",
      "            type='FCNMaskHead'),\r\n",
      "        mask_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            mask_thr_binary=0.5,\r\n",
      "            max_per_img=300,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.001),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            mask_size=28,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='MaskRCNN')\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(\r\n",
      "            img='/kaggle/input/hubmap-hacking-the-human-vasculature/test/'),\r\n",
      "        data_root='/kaggle/working/',\r\n",
      "        metainfo=dict(classes=(\r\n",
      "            'blood_vessel',\r\n",
      "            'glomerulus',\r\n",
      "            'unsure',\r\n",
      "        )),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1280,\r\n",
      "                1280,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='/kaggle/working/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1280,\r\n",
      "        1280,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "work_dir = './work_dirs/m0i'\r\n",
      "\r\n",
      "08/29 14:48:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "08/29 14:48:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "08/29 14:48:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpDetResults.\r\n",
      "Loads checkpoint by local backend from path: /kaggle/input/hubmap-weights/weights-hubmap/m0i.pth\r\n",
      "08/29 14:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /kaggle/input/hubmap-weights/weights-hubmap/m0i.pth\r\n",
      "08/29 14:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.01s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.00s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "08/29 14:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "| category     | mAP | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "| blood_vessel | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "| glomerulus   | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "| unsure       | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "08/29 14:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: -1.000 -1.000 -1.000 -1.000 -1.000 -1.000\r\n",
      "08/29 14:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Results has been saved to /kaggle/working/m0i.pkl.\r\n",
      "08/29 14:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1/1]    coco/blood_vessel_precision: nan  coco/glomerulus_precision: nan  coco/unsure_precision: nan  coco/bbox_mAP: -1.0000  coco/bbox_mAP_50: -1.0000  coco/bbox_mAP_75: -1.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: -1.0000  data_time: 0.1426  time: 4.7271\r\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\r\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\r\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\r\n",
      "08/29 14:49:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\r\n",
      "    CUDA available: True\r\n",
      "    numpy_random_seed: 363612116\r\n",
      "    GPU 0: Tesla P100-PCIE-16GB\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\r\n",
      "    GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0\r\n",
      "    PyTorch: 2.0.0\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 11.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 11.8\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_70,code=compute_70;-gencode;arch=compute_75,code=compute_75\r\n",
      "  - CuDNN 8.9\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.15.1\r\n",
      "    OpenCV: 4.8.0\r\n",
      "    MMEngine: 0.8.3\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 363612116\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "08/29 14:49:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\r\n",
      "backend_args = None\r\n",
      "custom_imports = dict(\r\n",
      "    allow_failed_imports=False, imports=[\r\n",
      "        'hubmap_modules',\r\n",
      "    ])\r\n",
      "data_root = '/kaggle/working/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "img_prefix = '/kaggle/input/hubmap-hacking-the-human-vasculature/test/'\r\n",
      "img_scale = (\r\n",
      "    1280,\r\n",
      "    1280,\r\n",
      ")\r\n",
      "launcher = 'none'\r\n",
      "load_from = '/kaggle/input/hubmap-weights/weights-hubmap/m1i.pth'\r\n",
      "metainfo = dict(classes=(\r\n",
      "    'blood_vessel',\r\n",
      "    'glomerulus',\r\n",
      "    'unsure',\r\n",
      "))\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        attn_drop_rate=0.0,\r\n",
      "        convert_weights=True,\r\n",
      "        depths=[\r\n",
      "            2,\r\n",
      "            2,\r\n",
      "            18,\r\n",
      "            2,\r\n",
      "        ],\r\n",
      "        drop_path_rate=0.2,\r\n",
      "        drop_rate=0.0,\r\n",
      "        embed_dims=96,\r\n",
      "        mlp_ratio=4,\r\n",
      "        num_heads=[\r\n",
      "            3,\r\n",
      "            6,\r\n",
      "            12,\r\n",
      "            24,\r\n",
      "        ],\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        patch_norm=True,\r\n",
      "        qk_scale=None,\r\n",
      "        qkv_bias=True,\r\n",
      "        type='SwinTransformer',\r\n",
      "        window_size=7,\r\n",
      "        with_cp=False),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=True,\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        pad_mask=True,\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            96,\r\n",
      "            192,\r\n",
      "            384,\r\n",
      "            768,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=3,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        mask_head=dict(\r\n",
      "            conv_out_channels=256,\r\n",
      "            in_channels=256,\r\n",
      "            loss_mask=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "            num_classes=3,\r\n",
      "            num_convs=4,\r\n",
      "            type='FCNMaskHead'),\r\n",
      "        mask_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            mask_thr_binary=0.5,\r\n",
      "            max_per_img=300,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.001),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            mask_size=28,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='MaskRCNN')\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(\r\n",
      "            img='/kaggle/input/hubmap-hacking-the-human-vasculature/test/'),\r\n",
      "        data_root='/kaggle/working/',\r\n",
      "        metainfo=dict(classes=(\r\n",
      "            'blood_vessel',\r\n",
      "            'glomerulus',\r\n",
      "            'unsure',\r\n",
      "        )),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1280,\r\n",
      "                1280,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='/kaggle/working/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1280,\r\n",
      "        1280,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "work_dir = './work_dirs/m0i'\r\n",
      "\r\n",
      "08/29 14:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "08/29 14:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "08/29 14:49:07 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpDetResults.\r\n",
      "Loads checkpoint by local backend from path: /kaggle/input/hubmap-weights/weights-hubmap/m1i.pth\r\n",
      "08/29 14:49:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /kaggle/input/hubmap-weights/weights-hubmap/m1i.pth\r\n",
      "08/29 14:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.00s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.00s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "08/29 14:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "| category     | mAP | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "| blood_vessel | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "| glomerulus   | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "| unsure       | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "08/29 14:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: -1.000 -1.000 -1.000 -1.000 -1.000 -1.000\r\n",
      "08/29 14:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Results has been saved to /kaggle/working/m1i.pkl.\r\n",
      "08/29 14:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1/1]    coco/blood_vessel_precision: nan  coco/glomerulus_precision: nan  coco/unsure_precision: nan  coco/bbox_mAP: -1.0000  coco/bbox_mAP_50: -1.0000  coco/bbox_mAP_75: -1.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: -1.0000  data_time: 0.1173  time: 2.0346\r\n"
     ]
    }
   ],
   "source": [
    "!python test.py \\\n",
    "    /kaggle/input/hubmap-resources/configs/m0i.py \\\n",
    "    /kaggle/input/hubmap-weights/weights-hubmap/m0i.pth \\\n",
    "    --out /kaggle/working/m0i.pkl\n",
    "\n",
    "!python test.py \\\n",
    "    /kaggle/input/hubmap-resources/configs/m0i.py \\\n",
    "    /kaggle/input/hubmap-weights/weights-hubmap/m1i.pth \\\n",
    "    --out /kaggle/working/m1i.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cee1157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:49:16.503090Z",
     "iopub.status.busy": "2023-08-29T14:49:16.502710Z",
     "iopub.status.idle": "2023-08-29T14:49:16.507542Z",
     "shell.execute_reply": "2023-08-29T14:49:16.506459Z"
    },
    "papermill": {
     "duration": 0.017656,
     "end_time": "2023-08-29T14:49:16.509628",
     "exception": false,
     "start_time": "2023-08-29T14:49:16.491972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python test.py \\\n",
    "#     /kaggle/input/hubmap-2023-configs/y0i.py \\\n",
    "#     /kaggle/input/hubmap-2023-checkpoints/y0i.pth \\\n",
    "#     --out /kaggle/working/y0i.pkl\n",
    "\n",
    "# !python test.py \\\n",
    "#     /kaggle/input/hubmap-2023-configs/y0i.py \\\n",
    "#     /kaggle/input/hubmap-2023-checkpoints/y1i.pth \\\n",
    "#     --out /kaggle/working/y1i.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffdde175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:49:16.530702Z",
     "iopub.status.busy": "2023-08-29T14:49:16.529735Z",
     "iopub.status.idle": "2023-08-29T14:50:13.238604Z",
     "shell.execute_reply": "2023-08-29T14:50:13.237387Z"
    },
    "papermill": {
     "duration": 56.722157,
     "end_time": "2023-08-29T14:50:13.241140",
     "exception": false,
     "start_time": "2023-08-29T14:49:16.518983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\r\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\r\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\r\n",
      "08/29 14:49:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\r\n",
      "    CUDA available: True\r\n",
      "    numpy_random_seed: 1015997071\r\n",
      "    GPU 0: Tesla P100-PCIE-16GB\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\r\n",
      "    GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0\r\n",
      "    PyTorch: 2.0.0\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 11.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 11.8\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_70,code=compute_70;-gencode;arch=compute_75,code=compute_75\r\n",
      "  - CuDNN 8.9\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.15.1\r\n",
      "    OpenCV: 4.8.0\r\n",
      "    MMEngine: 0.8.3\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1015997071\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "08/29 14:49:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\r\n",
      "backend_args = None\r\n",
      "custom_imports = dict(\r\n",
      "    allow_failed_imports=False, imports=[\r\n",
      "        'hubmap_modules',\r\n",
      "    ])\r\n",
      "data_root = '/kaggle/working/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "img_prefix = '/kaggle/input/hubmap-hacking-the-human-vasculature/test/'\r\n",
      "img_scale = (\r\n",
      "    768,\r\n",
      "    768,\r\n",
      ")\r\n",
      "launcher = 'none'\r\n",
      "load_from = '/kaggle/input/hubmap-weights/weights-hubmap/r0i.pth'\r\n",
      "metainfo = dict(classes=(\r\n",
      "    'blood_vessel',\r\n",
      "    'glomerulus',\r\n",
      "    'unsure',\r\n",
      "))\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\r\n",
      "        arch='P5',\r\n",
      "        channel_attention=True,\r\n",
      "        deepen_factor=1.33,\r\n",
      "        expand_ratio=0.5,\r\n",
      "        norm_cfg=dict(type='BN'),\r\n",
      "        type='CSPNeXt',\r\n",
      "        widen_factor=1.25),\r\n",
      "    bbox_head=dict(\r\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\r\n",
      "        anchor_generator=dict(\r\n",
      "            offset=0, strides=[\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ], type='MlvlPointGenerator'),\r\n",
      "        bbox_coder=dict(type='DistancePointBBoxCoder'),\r\n",
      "        exp_on_reg=True,\r\n",
      "        feat_channels=320,\r\n",
      "        in_channels=320,\r\n",
      "        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            beta=2.0,\r\n",
      "            loss_weight=1.0,\r\n",
      "            type='QualityFocalLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        norm_cfg=dict(type='BN'),\r\n",
      "        num_classes=3,\r\n",
      "        pred_kernel_size=1,\r\n",
      "        share_conv=True,\r\n",
      "        stacked_convs=2,\r\n",
      "        type='RTMDetSepBNHead',\r\n",
      "        with_objectness=False),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        batch_augments=None,\r\n",
      "        bgr_to_rgb=False,\r\n",
      "        mean=[\r\n",
      "            103.53,\r\n",
      "            116.28,\r\n",
      "            123.675,\r\n",
      "        ],\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            57.375,\r\n",
      "            57.12,\r\n",
      "            58.395,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    mask_head=dict(\r\n",
      "        conv_out_channels=256,\r\n",
      "        in_channels=320,\r\n",
      "        num_classes=1,\r\n",
      "        num_convs=7,\r\n",
      "        type='FCNMaskHead'),\r\n",
      "    neck=dict(\r\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\r\n",
      "        expand_ratio=0.5,\r\n",
      "        in_channels=[\r\n",
      "            320,\r\n",
      "            640,\r\n",
      "            1280,\r\n",
      "        ],\r\n",
      "        norm_cfg=dict(type='BN'),\r\n",
      "        num_csp_blocks=4,\r\n",
      "        out_channels=320,\r\n",
      "        type='CSPNeXtPAFPN'),\r\n",
      "    test_cfg=dict(\r\n",
      "        max_per_img=300,\r\n",
      "        min_bbox_size=0,\r\n",
      "        nms=dict(iou_threshold=0.65, type='nms'),\r\n",
      "        nms_pre=30000,\r\n",
      "        score_thr=0.001),\r\n",
      "    train_cfg=dict(\r\n",
      "        allowed_border=-1,\r\n",
      "        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),\r\n",
      "        debug=False,\r\n",
      "        mask_pos_mode='weighted_sum',\r\n",
      "        mask_roi_size=28,\r\n",
      "        pos_weight=-1),\r\n",
      "    type='RTMDetWithMaskHead')\r\n",
      "norm_cfg = dict(type='BN')\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(\r\n",
      "            img='/kaggle/input/hubmap-hacking-the-human-vasculature/test/'),\r\n",
      "        data_root='/kaggle/working/',\r\n",
      "        metainfo=dict(classes=(\r\n",
      "            'blood_vessel',\r\n",
      "            'glomerulus',\r\n",
      "            'unsure',\r\n",
      "        )),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                768,\r\n",
      "                768,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='/kaggle/working/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        768,\r\n",
      "        768,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "work_dir = './work_dirs/r0i'\r\n",
      "\r\n",
      "08/29 14:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "08/29 14:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "08/29 14:49:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpDetResults.\r\n",
      "Loads checkpoint by local backend from path: /kaggle/input/hubmap-weights/weights-hubmap/r0i.pth\r\n",
      "08/29 14:49:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /kaggle/input/hubmap-weights/weights-hubmap/r0i.pth\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3483.)\r\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n",
      "08/29 14:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.00s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.00s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "08/29 14:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "| category     | mAP | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "| blood_vessel | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "| glomerulus   | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "| unsure       | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "08/29 14:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: -1.000 -1.000 -1.000 -1.000 -1.000 -1.000\r\n",
      "08/29 14:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Results has been saved to /kaggle/working/r0i.pkl.\r\n",
      "08/29 14:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1/1]    coco/blood_vessel_precision: nan  coco/glomerulus_precision: nan  coco/unsure_precision: nan  coco/bbox_mAP: -1.0000  coco/bbox_mAP_50: -1.0000  coco/bbox_mAP_75: -1.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: -1.0000  data_time: 0.1104  time: 2.2302\r\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\r\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\r\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\r\n",
      "08/29 14:49:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\r\n",
      "    CUDA available: True\r\n",
      "    numpy_random_seed: 1037251799\r\n",
      "    GPU 0: Tesla P100-PCIE-16GB\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\r\n",
      "    GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0\r\n",
      "    PyTorch: 2.0.0\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 11.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 11.8\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_70,code=compute_70;-gencode;arch=compute_75,code=compute_75\r\n",
      "  - CuDNN 8.9\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.15.1\r\n",
      "    OpenCV: 4.8.0\r\n",
      "    MMEngine: 0.8.3\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1037251799\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "08/29 14:49:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\r\n",
      "backend_args = None\r\n",
      "custom_imports = dict(\r\n",
      "    allow_failed_imports=False, imports=[\r\n",
      "        'hubmap_modules',\r\n",
      "    ])\r\n",
      "data_root = '/kaggle/working/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "img_prefix = '/kaggle/input/hubmap-hacking-the-human-vasculature/test/'\r\n",
      "img_scale = (\r\n",
      "    768,\r\n",
      "    768,\r\n",
      ")\r\n",
      "launcher = 'none'\r\n",
      "load_from = '/kaggle/input/hubmap-weights/weights-hubmap/r1i.pth'\r\n",
      "metainfo = dict(classes=(\r\n",
      "    'blood_vessel',\r\n",
      "    'glomerulus',\r\n",
      "    'unsure',\r\n",
      "))\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\r\n",
      "        arch='P5',\r\n",
      "        channel_attention=True,\r\n",
      "        deepen_factor=1.33,\r\n",
      "        expand_ratio=0.5,\r\n",
      "        norm_cfg=dict(type='BN'),\r\n",
      "        type='CSPNeXt',\r\n",
      "        widen_factor=1.25),\r\n",
      "    bbox_head=dict(\r\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\r\n",
      "        anchor_generator=dict(\r\n",
      "            offset=0, strides=[\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ], type='MlvlPointGenerator'),\r\n",
      "        bbox_coder=dict(type='DistancePointBBoxCoder'),\r\n",
      "        exp_on_reg=True,\r\n",
      "        feat_channels=320,\r\n",
      "        in_channels=320,\r\n",
      "        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            beta=2.0,\r\n",
      "            loss_weight=1.0,\r\n",
      "            type='QualityFocalLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        norm_cfg=dict(type='BN'),\r\n",
      "        num_classes=3,\r\n",
      "        pred_kernel_size=1,\r\n",
      "        share_conv=True,\r\n",
      "        stacked_convs=2,\r\n",
      "        type='RTMDetSepBNHead',\r\n",
      "        with_objectness=False),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        batch_augments=None,\r\n",
      "        bgr_to_rgb=False,\r\n",
      "        mean=[\r\n",
      "            103.53,\r\n",
      "            116.28,\r\n",
      "            123.675,\r\n",
      "        ],\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            57.375,\r\n",
      "            57.12,\r\n",
      "            58.395,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    mask_head=dict(\r\n",
      "        conv_out_channels=256,\r\n",
      "        in_channels=320,\r\n",
      "        num_classes=1,\r\n",
      "        num_convs=7,\r\n",
      "        type='FCNMaskHead'),\r\n",
      "    neck=dict(\r\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\r\n",
      "        expand_ratio=0.5,\r\n",
      "        in_channels=[\r\n",
      "            320,\r\n",
      "            640,\r\n",
      "            1280,\r\n",
      "        ],\r\n",
      "        norm_cfg=dict(type='BN'),\r\n",
      "        num_csp_blocks=4,\r\n",
      "        out_channels=320,\r\n",
      "        type='CSPNeXtPAFPN'),\r\n",
      "    test_cfg=dict(\r\n",
      "        max_per_img=300,\r\n",
      "        min_bbox_size=0,\r\n",
      "        nms=dict(iou_threshold=0.65, type='nms'),\r\n",
      "        nms_pre=30000,\r\n",
      "        score_thr=0.001),\r\n",
      "    train_cfg=dict(\r\n",
      "        allowed_border=-1,\r\n",
      "        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),\r\n",
      "        debug=False,\r\n",
      "        mask_pos_mode='weighted_sum',\r\n",
      "        mask_roi_size=28,\r\n",
      "        pos_weight=-1),\r\n",
      "    type='RTMDetWithMaskHead')\r\n",
      "norm_cfg = dict(type='BN')\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(\r\n",
      "            img='/kaggle/input/hubmap-hacking-the-human-vasculature/test/'),\r\n",
      "        data_root='/kaggle/working/',\r\n",
      "        metainfo=dict(classes=(\r\n",
      "            'blood_vessel',\r\n",
      "            'glomerulus',\r\n",
      "            'unsure',\r\n",
      "        )),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                768,\r\n",
      "                768,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='/kaggle/working/test.json',\r\n",
      "    backend_args=None,\r\n",
      "    classwise=True,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        768,\r\n",
      "        768,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "work_dir = './work_dirs/r0i'\r\n",
      "\r\n",
      "08/29 14:50:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "08/29 14:50:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "08/29 14:50:03 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpDetResults.\r\n",
      "Loads checkpoint by local backend from path: /kaggle/input/hubmap-weights/weights-hubmap/r1i.pth\r\n",
      "08/29 14:50:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /kaggle/input/hubmap-weights/weights-hubmap/r1i.pth\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3483.)\r\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n",
      "08/29 14:50:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=0.00s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=0.00s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = -1.000\r\n",
      "08/29 14:50:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "| category     | mAP | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "| blood_vessel | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "| glomerulus   | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "| unsure       | nan | nan    | nan    | nan   | nan   | nan   |\r\n",
      "+--------------+-----+--------+--------+-------+-------+-------+\r\n",
      "08/29 14:50:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: -1.000 -1.000 -1.000 -1.000 -1.000 -1.000\r\n",
      "08/29 14:50:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Results has been saved to /kaggle/working/r1i.pkl.\r\n",
      "08/29 14:50:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1/1]    coco/blood_vessel_precision: nan  coco/glomerulus_precision: nan  coco/unsure_precision: nan  coco/bbox_mAP: -1.0000  coco/bbox_mAP_50: -1.0000  coco/bbox_mAP_75: -1.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: -1.0000  data_time: 0.1095  time: 2.1384\r\n"
     ]
    }
   ],
   "source": [
    "!python test.py \\\n",
    "    /kaggle/input/hubmap-resources/configs/r0i.py \\\n",
    "    /kaggle/input/hubmap-weights/weights-hubmap/r0i.pth \\\n",
    "    --out /kaggle/working/r0i.pkl\n",
    "\n",
    "!python test.py \\\n",
    "    /kaggle/input/hubmap-resources/configs/r0i.py \\\n",
    "    /kaggle/input/hubmap-weights/weights-hubmap/r1i.pth \\\n",
    "    --out /kaggle/working/r1i.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae986fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:13.268734Z",
     "iopub.status.busy": "2023-08-29T14:50:13.267629Z",
     "iopub.status.idle": "2023-08-29T14:50:13.272898Z",
     "shell.execute_reply": "2023-08-29T14:50:13.272009Z"
    },
    "papermill": {
     "duration": 0.021264,
     "end_time": "2023-08-29T14:50:13.274946",
     "exception": false,
     "start_time": "2023-08-29T14:50:13.253682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python test.py \\\n",
    "#     /kaggle/input/hubmap-2023-configs/s0i.py \\\n",
    "#     /kaggle/input/hubmap-2023-checkpoints/s0i.pth \\\n",
    "#     --out /kaggle/working/s0i.pkl\n",
    "\n",
    "# !python test.py \\\n",
    "#     /kaggle/input/hubmap-2023-configs/s0i.py \\\n",
    "#     /kaggle/input/hubmap-2023-checkpoints/s1i.pth \\\n",
    "#     --out /kaggle/working/s1i.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a86cbbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:13.300878Z",
     "iopub.status.busy": "2023-08-29T14:50:13.299874Z",
     "iopub.status.idle": "2023-08-29T14:50:13.304808Z",
     "shell.execute_reply": "2023-08-29T14:50:13.303922Z"
    },
    "papermill": {
     "duration": 0.020071,
     "end_time": "2023-08-29T14:50:13.306877",
     "exception": false,
     "start_time": "2023-08-29T14:50:13.286806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python test.py \\\n",
    "#     /kaggle/input/hubmap-2023-configs/sb0i.py \\\n",
    "#     /kaggle/input/hubmap-2023-checkpoints/sb0i.pth \\\n",
    "#     --out /kaggle/working/sb0i.pkl\n",
    "\n",
    "# !python test.py \\\n",
    "#     /kaggle/input/hubmap-2023-configs/sb0i.py \\\n",
    "#     /kaggle/input/hubmap-2023-checkpoints/sb1i.pth \\\n",
    "#     --out /kaggle/working/sb1i.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b00d430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:13.333230Z",
     "iopub.status.busy": "2023-08-29T14:50:13.332202Z",
     "iopub.status.idle": "2023-08-29T14:50:15.697803Z",
     "shell.execute_reply": "2023-08-29T14:50:15.696735Z"
    },
    "papermill": {
     "duration": 2.381592,
     "end_time": "2023-08-29T14:50:15.700565",
     "exception": false,
     "start_time": "2023-08-29T14:50:13.318973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import mmengine\n",
    "from ensemble_boxes import weighted_boxes_fusion\n",
    "\n",
    "results = [\n",
    "    mmengine.load(f'/kaggle/working/{name}.pkl') for name in\n",
    "    ['r0i', 'r1i', 'm0i', 'm1i',]#['r0i', 'r1i', 's0i', 's1i', 'm0i', 'm1i', 'y0i', 'y1i', 'sb0i', 'sb1i']\n",
    "]\n",
    "weights = [\n",
    "    2, 2, 1, 1#, 1, 1, 1, 1, 2, 2\n",
    "]\n",
    "\n",
    "SCALER = 10000\n",
    "IOU_THR = 0.7\n",
    "\n",
    "for rs in zip(*results):\n",
    "    # r['pred_instances']['bboxes'].shape =>   torch.Size([300, 4])   (when rs is from r0i)\n",
    "    # r['pred_instances']['scores'].shape =>   torch.Size([300])\n",
    "    # r['pred_instances']['labels'].shape =>   torch.Size([300])    \n",
    "    # r['pred_instances']['scores'][:10]  =>   tensor([0.5834, 0.5799, 0.5598, 0.5281, 0.4220, 0.4029, 0.4025, 0.3742, 0.3669, 0.3418])\n",
    "\n",
    "    boxes_list = [(r['pred_instances']['bboxes'] / SCALER).tolist() for r in rs]\n",
    "    scores_list = [r['pred_instances']['scores'].tolist() for r in rs]\n",
    "    labels_list = [r['pred_instances']['labels'].tolist() for r in rs]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes_list,\n",
    "                                                scores_list,\n",
    "                                                labels_list,\n",
    "                                                weights=weights,\n",
    "                                                iou_thr=IOU_THR,\n",
    "                                                conf_type='avg')\n",
    "    pred_instances = dict(\n",
    "        bboxes=torch.from_numpy(boxes).float() * SCALER,\n",
    "        scores=torch.from_numpy(scores).float(),\n",
    "        labels=torch.from_numpy(labels).long(),\n",
    "    )\n",
    "    rs[0]['pred_instances'] = pred_instances\n",
    "\n",
    "ensemble_result = results[0]\n",
    "\n",
    "mmengine.dump(ensemble_result, 'ensemble.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b9938",
   "metadata": {
    "papermill": {
     "duration": 0.011972,
     "end_time": "2023-08-29T14:50:15.724817",
     "exception": false,
     "start_time": "2023-08-29T14:50:15.712845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e2b2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:15.750889Z",
     "iopub.status.busy": "2023-08-29T14:50:15.750268Z",
     "iopub.status.idle": "2023-08-29T14:50:15.758148Z",
     "shell.execute_reply": "2023-08-29T14:50:15.757209Z"
    },
    "papermill": {
     "duration": 0.023869,
     "end_time": "2023-08-29T14:50:15.760731",
     "exception": false,
     "start_time": "2023-08-29T14:50:15.736862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_mask.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_mask.py\n",
    "\n",
    "import mmcv\n",
    "import mmengine\n",
    "import torch\n",
    "from mmengine.runner import load_checkpoint\n",
    "from mmengine.structures.instance_data import InstanceData\n",
    "from mmdet.registry import MODELS\n",
    "from mmdet.structures import DetDataSample\n",
    "from mmdet.structures.mask import encode_mask_results\n",
    "from mmdet.utils import register_all_modules\n",
    "\n",
    "register_all_modules()\n",
    "cfg = mmengine.Config.fromfile('/kaggle/input/hubmap-resources/configs/m0i.py')\n",
    "model = MODELS.build(cfg.model)\n",
    "load_checkpoint(model, '/kaggle/input/hubmap-weights/weights-hubmap/m1i.pth')\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_mask(result, input_size=(1440, 1440)):\n",
    "    img = mmcv.imread(result['img_path'])\n",
    "    img = mmcv.imresize(img, input_size)\n",
    "    batch_data = dict(\n",
    "        inputs=torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).cuda(),\n",
    "        data_samples=[\n",
    "            DetDataSample(metainfo=dict(img_id=result['img_id'],\n",
    "                                        ori_shape=(512, 512),\n",
    "                                        img_shape=(1440, 1440),\n",
    "                                        img_path=result['img_path'],\n",
    "                                        scale_factor=(1440 / 512, 1440 / 512)))\n",
    "        ])\n",
    "    batch_data = model.data_preprocessor(batch_data, False)\n",
    "    batch_data_inputs = batch_data['inputs']\n",
    "    batch_data_samples = batch_data['data_samples']\n",
    "    batch_img_metas = [\n",
    "        data_samples.metainfo for data_samples in batch_data_samples\n",
    "    ]\n",
    "    img_feats = model.extract_feat(batch_data_inputs)\n",
    "    # type(img_feats), len(img_feats) => <class 'tuple'>, 5\n",
    "    # img_feats[0].shape, img_feats[1].shape, img_feats[2].shape, img_feats[3].shape, img_feats[4].shape =>\n",
    "    # torch.Size([1, 256, 360, 360]), torch.Size([1, 256, 180, 180]), torch.Size([1, 256, 90, 90]), torch.Size([1, 256, 45, 45]), torch.Size([1, 256, 23, 23])\n",
    "    \n",
    "    img_result = InstanceData()\n",
    "    for k, v in result['pred_instances'].items():\n",
    "        # k ( torch.Size([619, 4]) )  => bboxes              (for first loop round)\n",
    "        # k ( torch.Size([619]) )     => scores              (for second loop round) \n",
    "        # k ( torch.Size([619]) )     => labels \n",
    "        img_result[k] = v.cuda()\n",
    "    img_result.bboxes *= 1440 / 512\n",
    "    results_list = model.roi_head.predict_mask(img_feats,\n",
    "                                               batch_img_metas, [img_result],\n",
    "                                               rescale=True)\n",
    "    out = results_list[0].cpu()\n",
    "    ret = dict(img_id=result['img_id'],\n",
    "               ori_shape=(512, 512),\n",
    "               img_shape=(1440, 1440),\n",
    "               img_path=result['img_path'],\n",
    "               scale_factor=(1440 / 512, 1440 / 512))\n",
    "    \n",
    "    # out['bboxes'].shape, out['labels'].shape, out['scores'].shape => \n",
    "    # torch.Size([619, 4]), torch.Size([619]), torch.Size([619])      \n",
    "    \n",
    "    ret['pred_instances'] = dict(\n",
    "        bboxes=out['bboxes'],\n",
    "        labels=out['labels'],\n",
    "        scores=out['scores'],\n",
    "        masks=encode_mask_results(out['masks'])\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "\n",
    "results = mmengine.load('/kaggle/working/ensemble.pkl')\n",
    "outputs = []\n",
    "for result in results:\n",
    "    output = predict_mask(result)\n",
    "    outputs.append(output)\n",
    "mmengine.dump(outputs, '/kaggle/working/ensemble_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97d8232d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:15.788175Z",
     "iopub.status.busy": "2023-08-29T14:50:15.786537Z",
     "iopub.status.idle": "2023-08-29T14:50:35.186639Z",
     "shell.execute_reply": "2023-08-29T14:50:35.185394Z"
    },
    "papermill": {
     "duration": 19.416825,
     "end_time": "2023-08-29T14:50:35.189535",
     "exception": false,
     "start_time": "2023-08-29T14:50:15.772710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\r\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\r\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\r\n",
      "Loads checkpoint by local backend from path: /kaggle/input/hubmap-weights/weights-hubmap/m1i.pth\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_mask.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da541626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:35.216988Z",
     "iopub.status.busy": "2023-08-29T14:50:35.216642Z",
     "iopub.status.idle": "2023-08-29T14:50:35.228460Z",
     "shell.execute_reply": "2023-08-29T14:50:35.227585Z"
    },
    "papermill": {
     "duration": 0.027967,
     "end_time": "2023-08-29T14:50:35.230477",
     "exception": false,
     "start_time": "2023-08-29T14:50:35.202510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray) -> t.Text:\n",
    "    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "\n",
    "    # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(\n",
    "            \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "            mask.dtype)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\n",
    "        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "        mask.shape)\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98d6ce33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:35.256603Z",
     "iopub.status.busy": "2023-08-29T14:50:35.255713Z",
     "iopub.status.idle": "2023-08-29T14:50:35.569730Z",
     "shell.execute_reply": "2023-08-29T14:50:35.568704Z"
    },
    "papermill": {
     "duration": 0.329659,
     "end_time": "2023-08-29T14:50:35.572281",
     "exception": false,
     "start_time": "2023-08-29T14:50:35.242622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2456100565.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if mask.dtype != np.bool:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mmcv\n",
    "import mmengine\n",
    "import pandas as pd\n",
    "import pycocotools.mask as mask_utils\n",
    "\n",
    "results = mmengine.load('/kaggle/working/ensemble_results.pkl')\n",
    "ids = []\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "prediction_strings = []\n",
    "for result in results:\n",
    "    img_path = result['img_path']\n",
    "    filename = os.path.basename(img_path)\n",
    "    ids.append(filename[:-4])\n",
    "    pred_instances = result['pred_instances']\n",
    "    bboxes = pred_instances['bboxes']\n",
    "    scores = pred_instances['scores'].tolist()\n",
    "    labels = pred_instances['labels'].tolist()\n",
    "    masks = pred_instances['masks']\n",
    "    instance_strings = []\n",
    "    for label, score, mask in zip(labels, scores, masks):\n",
    "        if label != 0:\n",
    "            continue\n",
    "        mask = mask_utils.decode(mask).astype(bool)\n",
    "        mask_string = encode_binary_mask(mask).decode('utf-8')\n",
    "        \n",
    "        instance_string = f'{label} {score} {mask_string}'\n",
    "        instance_strings.append(instance_string)\n",
    "    prediction_strings.append(' '.join(instance_strings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00e49c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:35.599101Z",
     "iopub.status.busy": "2023-08-29T14:50:35.598774Z",
     "iopub.status.idle": "2023-08-29T14:50:35.608236Z",
     "shell.execute_reply": "2023-08-29T14:50:35.607357Z"
    },
    "papermill": {
     "duration": 0.02511,
     "end_time": "2023-08-29T14:50:35.610304",
     "exception": false,
     "start_time": "2023-08-29T14:50:35.585194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(dict(\n",
    "    id=ids,\n",
    "    height=[HEIGHT] * len(ids),\n",
    "    width=[WIDTH] * len(ids),\n",
    "    prediction_string=prediction_strings\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "371c5d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T14:50:35.636337Z",
     "iopub.status.busy": "2023-08-29T14:50:35.635426Z",
     "iopub.status.idle": "2023-08-29T14:50:35.648229Z",
     "shell.execute_reply": "2023-08-29T14:50:35.647367Z"
    },
    "papermill": {
     "duration": 0.027992,
     "end_time": "2023-08-29T14:50:35.650431",
     "exception": false,
     "start_time": "2023-08-29T14:50:35.622439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7cc99",
   "metadata": {
    "papermill": {
     "duration": 0.011741,
     "end_time": "2023-08-29T14:50:35.674279",
     "exception": false,
     "start_time": "2023-08-29T14:50:35.662538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 293.978711,
   "end_time": "2023-08-29T14:50:36.910600",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-29T14:45:42.931889",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
